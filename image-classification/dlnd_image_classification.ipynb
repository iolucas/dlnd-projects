{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 0:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 6 Name: frog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+4ZgtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa65f8d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 0\n",
    "\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n",
    "\n",
    "#10000 images (range index 0-9999) per batch\n",
    "#5 batches\n",
    "#already shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    x = x / 255\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "one_hot_map = [\n",
    "    [1,0,0,0,0,0,0,0,0,0], #0\n",
    "    [0,1,0,0,0,0,0,0,0,0], #1\n",
    "    [0,0,1,0,0,0,0,0,0,0], #2\n",
    "    [0,0,0,1,0,0,0,0,0,0], #3\n",
    "    [0,0,0,0,1,0,0,0,0,0], #4\n",
    "    [0,0,0,0,0,1,0,0,0,0], #5\n",
    "    [0,0,0,0,0,0,1,0,0,0], #6\n",
    "    [0,0,0,0,0,0,0,1,0,0], #7\n",
    "    [0,0,0,0,0,0,0,0,1,0], #8\n",
    "    [0,0,0,0,0,0,0,0,0,1]  #9\n",
    "]\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot_x = [one_hot_map[i] for i in x]\n",
    "    return np.array(one_hot_x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    tensor_shape = list(image_shape)\n",
    "    tensor_shape.insert(0,None)\n",
    "    image_tensor = tf.placeholder(dtype=tf.float32, shape=tensor_shape, name=\"x\")\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    label_tensor = tf.placeholder(dtype=tf.float32, shape=[None, n_classes], name=\"y\")\n",
    "    \n",
    "    return label_tensor\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob_tensor = tf.placeholder(dtype=tf.float32, name=\"keep_prob\")\n",
    "    return keep_prob_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    #Get shapes \n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    conv_weights_shape = [conv_ksize[0], conv_ksize[1], x_tensor_shape[3], conv_num_outputs]\n",
    "    conv_strides_full = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    pool_ksize_full = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_strides_full = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    \n",
    "    #Create variables\n",
    "    conv_weights = tf.Variable(tf.truncated_normal(conv_weights_shape, stddev=0.05)) #aka conv_filter\n",
    "    conv_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "\n",
    "    #Calculate stuff\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, conv_weights, conv_strides_full, \"SAME\")\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, conv_bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, pool_ksize_full, pool_strides_full, \"SAME\")\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    new_length = 1\n",
    "    for value in x_tensor_shape[1:]:\n",
    "        new_length *= value\n",
    "    \n",
    "    x_tensor_flatten = tf.reshape(x_tensor, [-1, new_length])\n",
    "    return x_tensor_flatten\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    weights_shape = [x_tensor_shape[1], num_outputs]\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal(weights_shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    fully_conn_layer = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    fully_conn_layer = tf.nn.relu(fully_conn_layer)\n",
    "    \n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor_shape = x_tensor.get_shape().as_list()\n",
    "    weights_shape = [x_tensor_shape[1], num_outputs]\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal(weights_shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n",
      "(?, 10)\n",
      "(?,)\n",
      "()\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    n_network = x\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    n_network = conv2d_maxpool(n_network, 20, (4,4), (2,2), (2,2), (2,2))\n",
    "    #print(n_network.get_shape())\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    n_network = flatten(n_network)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    n_network = fully_conn(n_network, 200)\n",
    "    n_network = tf.nn.dropout(n_network, keep_prob)\n",
    "    n_network = fully_conn(n_network, 100)\n",
    "    n_network = fully_conn(n_network, 50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    n_network = output(n_network, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return n_network\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "print(logits.get_shape())\n",
    "print(y.get_shape())\n",
    "# Loss and Optimizer\n",
    "sc = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "print(sc.get_shape())\n",
    "cost = tf.reduce_mean(sc)\n",
    "print(cost.get_shape())\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x:feature_batch, \n",
    "        y:label_batch, \n",
    "        keep_prob:keep_probability\n",
    "    })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1\n",
    "    })\n",
    "    \n",
    "    valid_accuracy = session.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1\n",
    "    })\n",
    "    \n",
    "    print(\"Loss: {} Accuracy: {}\".format(loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 65\n",
    "batch_size = 2048\n",
    "keep_probability = 0.5\n",
    "#set epochs bigger until the thing stops improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2980315685272217 Accuracy: 0.13679999113082886\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.278846025466919 Accuracy: 0.1581999808549881\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.2260279655456543 Accuracy: 0.17260000109672546\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.134284257888794 Accuracy: 0.1897999793291092\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.0871963500976562 Accuracy: 0.22220000624656677\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.040566921234131 Accuracy: 0.2409999966621399\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.9906060695648193 Accuracy: 0.265999972820282\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.9529178142547607 Accuracy: 0.2818000018596649\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.90425705909729 Accuracy: 0.29440000653266907\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.8686039447784424 Accuracy: 0.30059999227523804\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.8334118127822876 Accuracy: 0.3240000009536743\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.811018943786621 Accuracy: 0.3402000069618225\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.7814525365829468 Accuracy: 0.3503999710083008\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.7470577955245972 Accuracy: 0.35479995608329773\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.720841646194458 Accuracy: 0.3587999939918518\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.7017903327941895 Accuracy: 0.368399977684021\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.6816432476043701 Accuracy: 0.3676000237464905\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.6592061519622803 Accuracy: 0.3771999776363373\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.640531063079834 Accuracy: 0.3837999701499939\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.6146340370178223 Accuracy: 0.39239996671676636\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.5962204933166504 Accuracy: 0.38999998569488525\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.572317361831665 Accuracy: 0.40199998021125793\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.5481388568878174 Accuracy: 0.407399982213974\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.5309818983078003 Accuracy: 0.4161999523639679\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.5164432525634766 Accuracy: 0.41819995641708374\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.495635986328125 Accuracy: 0.42799997329711914\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.4733223915100098 Accuracy: 0.42579999566078186\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.460221767425537 Accuracy: 0.43359997868537903\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.4545385837554932 Accuracy: 0.4398000240325928\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.443876028060913 Accuracy: 0.4355999529361725\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.4337419271469116 Accuracy: 0.4407999813556671\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.4087824821472168 Accuracy: 0.4407999515533447\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.3897123336791992 Accuracy: 0.44919997453689575\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.3708399534225464 Accuracy: 0.454399973154068\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.3537700176239014 Accuracy: 0.45319992303848267\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.3346152305603027 Accuracy: 0.4585999548435211\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.3213505744934082 Accuracy: 0.45639997720718384\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.316111445426941 Accuracy: 0.46279993653297424\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.2993531227111816 Accuracy: 0.4647999703884125\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.2881042957305908 Accuracy: 0.46459996700286865\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.2710473537445068 Accuracy: 0.4681999981403351\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.2604951858520508 Accuracy: 0.46939998865127563\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.2484040260314941 Accuracy: 0.47339996695518494\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.2359908819198608 Accuracy: 0.4711999297142029\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.2264809608459473 Accuracy: 0.47419995069503784\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.209191083908081 Accuracy: 0.4797999858856201\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.1948895454406738 Accuracy: 0.47919997572898865\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.1853039264678955 Accuracy: 0.4811999499797821\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.1690903902053833 Accuracy: 0.48799997568130493\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.1576069593429565 Accuracy: 0.48420000076293945\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 1.144744873046875 Accuracy: 0.4829999506473541\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 1.1330904960632324 Accuracy: 0.49059993028640747\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 1.1191506385803223 Accuracy: 0.4973999261856079\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 1.1078119277954102 Accuracy: 0.4915999472141266\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 1.0932148694992065 Accuracy: 0.4965999126434326\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 1.083568811416626 Accuracy: 0.49619996547698975\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 1.0714442729949951 Accuracy: 0.5003999471664429\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 1.0597338676452637 Accuracy: 0.5029999613761902\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 1.0493848323822021 Accuracy: 0.5031999349594116\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 1.0351746082305908 Accuracy: 0.502799928188324\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 1.0308029651641846 Accuracy: 0.5049999356269836\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 1.0243699550628662 Accuracy: 0.5021999478340149\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 1.0004781484603882 Accuracy: 0.5097999572753906\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.994830846786499 Accuracy: 0.5091999769210815\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.9783265590667725 Accuracy: 0.5119999647140503\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2923736572265625 Accuracy: 0.10460000485181808\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.267219066619873 Accuracy: 0.15639998018741608\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.211611747741699 Accuracy: 0.17739999294281006\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.121741771697998 Accuracy: 0.17499998211860657\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.0931949615478516 Accuracy: 0.20539997518062592\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.081684112548828 Accuracy: 0.2449999749660492\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.027298927307129 Accuracy: 0.24779999256134033\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.9976855516433716 Accuracy: 0.24939997494220734\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.950542688369751 Accuracy: 0.2513999938964844\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.9514331817626953 Accuracy: 0.2667999863624573\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.9569498300552368 Accuracy: 0.2799999713897705\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.9022879600524902 Accuracy: 0.2837999761104584\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.8513420820236206 Accuracy: 0.28939998149871826\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.8357486724853516 Accuracy: 0.3118000030517578\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.8498157262802124 Accuracy: 0.30580002069473267\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.8262383937835693 Accuracy: 0.31119999289512634\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.7817012071609497 Accuracy: 0.33160001039505005\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.7364240884780884 Accuracy: 0.3423999845981598\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.720533847808838 Accuracy: 0.3619999885559082\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.7712621688842773 Accuracy: 0.34960001707077026\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.7511625289916992 Accuracy: 0.3593999743461609\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.7010772228240967 Accuracy: 0.3611999452114105\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.6528475284576416 Accuracy: 0.37459999322891235\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.6428847312927246 Accuracy: 0.382999986410141\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.7132307291030884 Accuracy: 0.3669999837875366\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.6685051918029785 Accuracy: 0.3887999951839447\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.6349509954452515 Accuracy: 0.3967999815940857\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.5859417915344238 Accuracy: 0.39479997754096985\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.578791856765747 Accuracy: 0.4009999930858612\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.6504749059677124 Accuracy: 0.3967999815940857\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.6136049032211304 Accuracy: 0.4097999632358551\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.5762253999710083 Accuracy: 0.4131999611854553\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.5376067161560059 Accuracy: 0.4147999584674835\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.5211981534957886 Accuracy: 0.417199969291687\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.6005059480667114 Accuracy: 0.41179996728897095\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.561241626739502 Accuracy: 0.4277999699115753\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.527875542640686 Accuracy: 0.43199998140335083\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.4742705821990967 Accuracy: 0.4318000078201294\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.4765350818634033 Accuracy: 0.4357999563217163\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.553078532218933 Accuracy: 0.4291999936103821\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.508065938949585 Accuracy: 0.4447999596595764\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.4881469011306763 Accuracy: 0.44579994678497314\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.4228754043579102 Accuracy: 0.44599995017051697\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.4438914060592651 Accuracy: 0.4471999704837799\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.5042535066604614 Accuracy: 0.4505999684333801\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.453873872756958 Accuracy: 0.46039995551109314\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.4383951425552368 Accuracy: 0.46299996972084045\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.3764398097991943 Accuracy: 0.46379995346069336\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.4039582014083862 Accuracy: 0.460999995470047\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.4711253643035889 Accuracy: 0.46000000834465027\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.4338746070861816 Accuracy: 0.47019997239112854\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.393491506576538 Accuracy: 0.4753999412059784\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.341694951057434 Accuracy: 0.473999947309494\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.3640336990356445 Accuracy: 0.4771999716758728\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.4099774360656738 Accuracy: 0.4809999465942383\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.3910101652145386 Accuracy: 0.48539993166923523\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.356177568435669 Accuracy: 0.49139994382858276\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.3009028434753418 Accuracy: 0.4875999689102173\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.3277167081832886 Accuracy: 0.4925999343395233\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.376946210861206 Accuracy: 0.4891999661922455\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.3608503341674805 Accuracy: 0.49379995465278625\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.3229093551635742 Accuracy: 0.5003999471664429\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.2766697406768799 Accuracy: 0.4963999390602112\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.3012433052062988 Accuracy: 0.4995999336242676\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.3479950428009033 Accuracy: 0.4957999289035797\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.3415029048919678 Accuracy: 0.5039999485015869\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.3049256801605225 Accuracy: 0.5051999092102051\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.2588024139404297 Accuracy: 0.5015999674797058\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.2843528985977173 Accuracy: 0.5013999342918396\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.3244775533676147 Accuracy: 0.5013999938964844\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.3303343057632446 Accuracy: 0.5125999450683594\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.2904338836669922 Accuracy: 0.5019999742507935\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.239974856376648 Accuracy: 0.5073999762535095\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.2482091188430786 Accuracy: 0.5123999118804932\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.2786909341812134 Accuracy: 0.5151999592781067\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.2887324094772339 Accuracy: 0.5191999673843384\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.2507058382034302 Accuracy: 0.5211999416351318\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.1938985586166382 Accuracy: 0.5175999402999878\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.2232725620269775 Accuracy: 0.5239999890327454\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.2565369606018066 Accuracy: 0.5165999531745911\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.273689866065979 Accuracy: 0.525399923324585\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.231768012046814 Accuracy: 0.525999903678894\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.1767103672027588 Accuracy: 0.5233999490737915\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.2121529579162598 Accuracy: 0.5249999761581421\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.2415951490402222 Accuracy: 0.5171999931335449\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.249042272567749 Accuracy: 0.5353999733924866\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.2131470441818237 Accuracy: 0.530799925327301\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.1544461250305176 Accuracy: 0.530799925327301\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.1820975542068481 Accuracy: 0.5313999056816101\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.2112407684326172 Accuracy: 0.5317999720573425\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.2364354133605957 Accuracy: 0.5329999327659607\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.194514513015747 Accuracy: 0.53739994764328\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.1361045837402344 Accuracy: 0.5339999198913574\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.163824439048767 Accuracy: 0.5343999862670898\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.1946589946746826 Accuracy: 0.5349999070167542\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.215874433517456 Accuracy: 0.5403999090194702\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.173862338066101 Accuracy: 0.5389999151229858\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.1105222702026367 Accuracy: 0.538599967956543\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.140681505203247 Accuracy: 0.5379999279975891\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.1634345054626465 Accuracy: 0.539199948310852\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.1929702758789062 Accuracy: 0.5433999300003052\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.1603469848632812 Accuracy: 0.5399999618530273\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.099209189414978 Accuracy: 0.5443999171257019\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.1196050643920898 Accuracy: 0.546799898147583\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.1503671407699585 Accuracy: 0.5409998893737793\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.1826175451278687 Accuracy: 0.5507999658584595\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.1423296928405762 Accuracy: 0.5475999116897583\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.0781745910644531 Accuracy: 0.5459998846054077\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.1085882186889648 Accuracy: 0.546799898147583\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.1306966543197632 Accuracy: 0.5481999516487122\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.16445791721344 Accuracy: 0.5477998852729797\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.1245005130767822 Accuracy: 0.5447999835014343\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.070645809173584 Accuracy: 0.5491999387741089\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.090126872062683 Accuracy: 0.5509998798370361\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.1062136888504028 Accuracy: 0.5493999719619751\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.1438531875610352 Accuracy: 0.5559998750686646\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.104356050491333 Accuracy: 0.556399941444397\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.0339891910552979 Accuracy: 0.5583999156951904\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.0647730827331543 Accuracy: 0.5591999292373657\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.0796175003051758 Accuracy: 0.553399920463562\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.1336660385131836 Accuracy: 0.5527999401092529\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.0800423622131348 Accuracy: 0.5567998886108398\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.0179940462112427 Accuracy: 0.555199921131134\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.0480265617370605 Accuracy: 0.5623999238014221\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.0664888620376587 Accuracy: 0.5601999163627625\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.1033469438552856 Accuracy: 0.5557999610900879\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.0664244890213013 Accuracy: 0.5567999482154846\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.0145305395126343 Accuracy: 0.5585999488830566\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.0405110120773315 Accuracy: 0.5609999299049377\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.0551775693893433 Accuracy: 0.556399941444397\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.1008188724517822 Accuracy: 0.5615999698638916\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.0643904209136963 Accuracy: 0.5549999475479126\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.9956445693969727 Accuracy: 0.5597999691963196\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.023427963256836 Accuracy: 0.5627999305725098\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.0246546268463135 Accuracy: 0.5673999190330505\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.076515793800354 Accuracy: 0.5639999508857727\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.0330156087875366 Accuracy: 0.5621999502182007\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.9716710448265076 Accuracy: 0.5671999454498291\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.9955727458000183 Accuracy: 0.5669999122619629\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.0098161697387695 Accuracy: 0.5657998919487\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.049820065498352 Accuracy: 0.5679999589920044\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.0177189111709595 Accuracy: 0.559999942779541\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.9495447874069214 Accuracy: 0.5659998655319214\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.9799237251281738 Accuracy: 0.5693999528884888\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.9831093549728394 Accuracy: 0.5729999542236328\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.0422859191894531 Accuracy: 0.5763999223709106\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.0033156871795654 Accuracy: 0.5671999454498291\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.9376481771469116 Accuracy: 0.5697999596595764\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.9723321795463562 Accuracy: 0.5705999135971069\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.9813783168792725 Accuracy: 0.5713999271392822\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.020560383796692 Accuracy: 0.5747999548912048\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.9868014454841614 Accuracy: 0.5733999609947205\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.912865936756134 Accuracy: 0.5779999494552612\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.9591013193130493 Accuracy: 0.5763999223709106\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.9537041187286377 Accuracy: 0.5759999752044678\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.003684639930725 Accuracy: 0.5767998695373535\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.9783691167831421 Accuracy: 0.5729999542236328\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.8924086689949036 Accuracy: 0.5757999420166016\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.935293436050415 Accuracy: 0.5757998824119568\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.9367836117744446 Accuracy: 0.5859999060630798\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.9900410175323486 Accuracy: 0.5781998634338379\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.9526889324188232 Accuracy: 0.577799916267395\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.8866908550262451 Accuracy: 0.5843998789787292\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.9178673624992371 Accuracy: 0.5841999053955078\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.916832685470581 Accuracy: 0.5839999914169312\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.9714574813842773 Accuracy: 0.5833998918533325\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.9432896971702576 Accuracy: 0.5761999487876892\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.8616443276405334 Accuracy: 0.5845999121665955\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.9045727849006653 Accuracy: 0.579599916934967\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.9064826369285583 Accuracy: 0.5849999189376831\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.9515255689620972 Accuracy: 0.5859999656677246\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.9146052002906799 Accuracy: 0.5809999704360962\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.8536150455474854 Accuracy: 0.5859999060630798\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.8825715184211731 Accuracy: 0.5867999792098999\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.8897897005081177 Accuracy: 0.5917999148368835\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.9308345317840576 Accuracy: 0.5885999202728271\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.9087193608283997 Accuracy: 0.5859999656677246\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.8320204019546509 Accuracy: 0.5953999757766724\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.8727500438690186 Accuracy: 0.5917999148368835\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.8729696273803711 Accuracy: 0.5931998491287231\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.9232593178749084 Accuracy: 0.5935999751091003\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.8925386071205139 Accuracy: 0.5887998938560486\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.8196296095848083 Accuracy: 0.5951998829841614\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.8493709564208984 Accuracy: 0.5913999080657959\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.857345461845398 Accuracy: 0.5977998971939087\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.903877854347229 Accuracy: 0.5941998958587646\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.879882276058197 Accuracy: 0.5867999196052551\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.8235459923744202 Accuracy: 0.5927999019622803\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.8323066830635071 Accuracy: 0.5981998443603516\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.848019003868103 Accuracy: 0.5981998443603516\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.8842628002166748 Accuracy: 0.5993999242782593\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.8668788075447083 Accuracy: 0.5869999527931213\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.795444130897522 Accuracy: 0.5997998714447021\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.8201295137405396 Accuracy: 0.596799910068512\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.8287066221237183 Accuracy: 0.5951999425888062\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.865529477596283 Accuracy: 0.5929998755455017\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.8430498242378235 Accuracy: 0.5937999486923218\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.7843050956726074 Accuracy: 0.6033998727798462\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.8040216565132141 Accuracy: 0.5979999303817749\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.8082582950592041 Accuracy: 0.5975998640060425\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.8491706848144531 Accuracy: 0.5973999500274658\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.8480676412582397 Accuracy: 0.5949999094009399\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.768812894821167 Accuracy: 0.5991998910903931\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.7953702211380005 Accuracy: 0.5961999297142029\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.7876788973808289 Accuracy: 0.6019999384880066\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.8330549001693726 Accuracy: 0.6053999066352844\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.8254814147949219 Accuracy: 0.5949999094009399\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.757264256477356 Accuracy: 0.601599931716919\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.7772940993309021 Accuracy: 0.6007999181747437\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.7695616483688354 Accuracy: 0.6075998544692993\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.813326895236969 Accuracy: 0.6053999662399292\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.8113455176353455 Accuracy: 0.5951998233795166\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.7450842261314392 Accuracy: 0.6061998605728149\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.7762983441352844 Accuracy: 0.5997999310493469\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.7606404423713684 Accuracy: 0.6035999059677124\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.8127315044403076 Accuracy: 0.601599931716919\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.7938741445541382 Accuracy: 0.5997998714447021\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.7434897422790527 Accuracy: 0.6005999445915222\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.7647035717964172 Accuracy: 0.5963999032974243\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.7427921295166016 Accuracy: 0.6073999404907227\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.8131536245346069 Accuracy: 0.6027998924255371\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.7762196063995361 Accuracy: 0.6031998991966248\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.7436872720718384 Accuracy: 0.5947999358177185\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.7359732389450073 Accuracy: 0.6119999289512634\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.7548894882202148 Accuracy: 0.6037999391555786\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.7846323251724243 Accuracy: 0.6045998930931091\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.7828196883201599 Accuracy: 0.6019998788833618\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.7200387716293335 Accuracy: 0.6103999018669128\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.733657717704773 Accuracy: 0.6099998950958252\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.7269585728645325 Accuracy: 0.6085999608039856\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.7699673771858215 Accuracy: 0.612799882888794\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.7543765902519226 Accuracy: 0.6107999086380005\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.702457070350647 Accuracy: 0.6107999682426453\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.7159063816070557 Accuracy: 0.6175999045372009\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.7111663818359375 Accuracy: 0.612799882888794\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.7537456750869751 Accuracy: 0.6129999160766602\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.7383166551589966 Accuracy: 0.6097999811172485\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.7022951245307922 Accuracy: 0.6065999269485474\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.7100811004638672 Accuracy: 0.6133999228477478\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.6999740600585938 Accuracy: 0.6147999167442322\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.7455204725265503 Accuracy: 0.6185998916625977\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.733123779296875 Accuracy: 0.6163999438285828\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.6733091473579407 Accuracy: 0.6117998957633972\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.680944561958313 Accuracy: 0.614599883556366\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.6819462776184082 Accuracy: 0.6191998720169067\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.7221510410308838 Accuracy: 0.6223999261856079\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.7190530896186829 Accuracy: 0.6149998903274536\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.6697786450386047 Accuracy: 0.6123999357223511\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.6735121011734009 Accuracy: 0.6163999438285828\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.6772666573524475 Accuracy: 0.614599883556366\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.7139317989349365 Accuracy: 0.6183999180793762\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.7174358367919922 Accuracy: 0.6115999221801758\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.6564866304397583 Accuracy: 0.6129998564720154\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.663889467716217 Accuracy: 0.6179999113082886\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.6647137403488159 Accuracy: 0.6161999106407166\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.7051395177841187 Accuracy: 0.6175999641418457\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.7010839581489563 Accuracy: 0.6135998964309692\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.6402991414070129 Accuracy: 0.6189998984336853\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.6417271494865417 Accuracy: 0.6223999261856079\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.6465448141098022 Accuracy: 0.6195999383926392\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.696353554725647 Accuracy: 0.6191998720169067\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.6841033697128296 Accuracy: 0.6183999180793762\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.6354761719703674 Accuracy: 0.6199999451637268\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.6257784366607666 Accuracy: 0.6187999248504639\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.6299223899841309 Accuracy: 0.6267998814582825\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.6745195388793945 Accuracy: 0.6235998868942261\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.6738817691802979 Accuracy: 0.6205999255180359\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.6190272569656372 Accuracy: 0.6219999194145203\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.6065331101417542 Accuracy: 0.6209999322891235\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.6256359815597534 Accuracy: 0.6239999532699585\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.6634560823440552 Accuracy: 0.624799907207489\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.6609578132629395 Accuracy: 0.6195999383926392\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.6153395175933838 Accuracy: 0.6241999268531799\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.599039614200592 Accuracy: 0.6237999200820923\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.613627552986145 Accuracy: 0.6215999722480774\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.6499278545379639 Accuracy: 0.6249998807907104\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.6470374464988708 Accuracy: 0.6229999661445618\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.6095998883247375 Accuracy: 0.6211998462677002\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.5861745476722717 Accuracy: 0.6255999207496643\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.6103980541229248 Accuracy: 0.6263999342918396\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.6422677040100098 Accuracy: 0.6275998950004578\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.6340043544769287 Accuracy: 0.6249998807907104\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.6086822152137756 Accuracy: 0.6251998543739319\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.5809595584869385 Accuracy: 0.6237999200820923\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.5922502875328064 Accuracy: 0.6279999017715454\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.6228042244911194 Accuracy: 0.6299998760223389\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.6246422529220581 Accuracy: 0.6225998997688293\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.5899478793144226 Accuracy: 0.630599856376648\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.5713217854499817 Accuracy: 0.6291998624801636\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.5735597014427185 Accuracy: 0.6225998997688293\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.6188360452651978 Accuracy: 0.6279999017715454\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.6258487701416016 Accuracy: 0.6157999038696289\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.5779716372489929 Accuracy: 0.6179999113082886\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.5641237497329712 Accuracy: 0.6279999017715454\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.574120044708252 Accuracy: 0.6235999464988708\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.6077998280525208 Accuracy: 0.6275999546051025\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.6106865406036377 Accuracy: 0.6221998929977417\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.566304087638855 Accuracy: 0.6261998414993286\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.546919584274292 Accuracy: 0.627799928188324\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.5557321310043335 Accuracy: 0.6309999227523804\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss: 0.5885444283485413 Accuracy: 0.6271998882293701\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss: 0.5959307551383972 Accuracy: 0.6257998943328857\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss: 0.5629780292510986 Accuracy: 0.6301999092102051\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss: 0.5366292595863342 Accuracy: 0.6257999539375305\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss: 0.542079746723175 Accuracy: 0.625999927520752\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss: 0.5816212296485901 Accuracy: 0.6313998699188232\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss: 0.5953847169876099 Accuracy: 0.6219999194145203\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss: 0.5487244129180908 Accuracy: 0.6239999532699585\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss: 0.5289450287818909 Accuracy: 0.6277998685836792\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss: 0.5440993905067444 Accuracy: 0.6263998746871948\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss: 0.5662882924079895 Accuracy: 0.6309999227523804\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss: 0.5856327414512634 Accuracy: 0.6251999139785767\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss: 0.5384297966957092 Accuracy: 0.6243999004364014\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss: 0.5152027010917664 Accuracy: 0.6261998414993286\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss: 0.5305700898170471 Accuracy: 0.6283998489379883\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss: 0.5598919987678528 Accuracy: 0.6339998841285706\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss: 0.5690324306488037 Accuracy: 0.6283998489379883\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss: 0.530872106552124 Accuracy: 0.6337999105453491\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss: 0.5050675868988037 Accuracy: 0.6271998882293701\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss: 0.5343180894851685 Accuracy: 0.6269999146461487\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss: 0.549458920955658 Accuracy: 0.6325998902320862\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss: 0.5647380352020264 Accuracy: 0.6341999173164368\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss: 0.5329018235206604 Accuracy: 0.6255998611450195\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss: 0.49973151087760925 Accuracy: 0.6331998705863953\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss: 0.5131723880767822 Accuracy: 0.6259998679161072\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6293884754180908\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngmMRERERkUjBsYiIiIhI9P8BjrPmNRIrX6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd67e639b0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
